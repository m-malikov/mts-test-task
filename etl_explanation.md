# Описание решения

## Загрузка данных
Пусть каждые три минуты по ftp приходит JSON-дамп размером 300мб. 
Запускаем каждые три минуты Python-скрипт, который парсит ещё не обработанные JSON-файлы,
извлекает из них нужные значения и тут же считает оценку для текста твита.
Извлеченные значения помещаются в базу данных, по одной строке на твит.
JSON-файлы можно удалять достаточно часто, например раз в сутки (за сутки должно накопиться примерно ~150гб данных)

## Обработка данных
Каждые сутки подсчитывать с помощью SQL-запроса среднюю оценку и количество твитов по странам, локациям, пользователям.

## Хранение результатов
Записывать их в отдельную таблицу. Сами твиты, в зависимости от задачи, либо периодически удалять, либо хранить без текста.
Если результаты и твиты будут собираться за достаточно долгое время, можно перейти на NoSQL базу данных.
